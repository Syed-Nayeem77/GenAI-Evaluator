GenAI Evaluator

This project evaluates the quality of generative AI outputs using standard NLP metrics like BLEU and BERTScore.

Features
- BLEU Score for n-gram overlap
- BERTScore for semantic similarity
- Clean architecture for integration
- Easy CLI or script-based usage

Usage

```bash
python main.py


Evaluation Results:
BLEU: 0.82
{'precision': 0.9418, 'recall': 0.9393, 'f1': 0.9406}
