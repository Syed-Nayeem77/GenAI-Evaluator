GenAI Evaluator

This project evaluates the quality of generative AI outputs using standard NLP metrics like BLEU and BERTScore.

Features
- BLEU Score for n-gram overlap
- BERTScore for semantic similarity
- Clean architecture for integration
- Easy CLI or script-based usage

Usage

```bash
python main.py


Evaluation Results:
BLEU: 0.82
BERTScore: {'precision': 0.89, 'recall': 0.91, 'f1': 0.90}
